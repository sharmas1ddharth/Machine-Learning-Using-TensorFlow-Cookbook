{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Leay3d4m0tBk"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "37HuA90j0yxc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental import RandomFourierFeatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JlrpXjDp4j_Q"
      },
      "outputs": [],
      "source": [
        "columns = ['sample_code', 'clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity', 'marginal_adhesion', 'single_epithelial_cell_size',\n",
        "             'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses', 'class']\n",
        "data = pd.read_csv(\"../data/breast-cancer-wisconsin.data\", header=None, names=columns, na_values=[np.nan, '?'])\n",
        "data = data.fillna(data.median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HtW_ErUNdQuD"
      },
      "outputs": [],
      "source": [
        "np.random.seed(1)\n",
        "train = data.sample(frac=0.8).copy()\n",
        "y_train = (train['class'] == 4).astype(int)\n",
        "train.drop(['sample_code', 'class'], axis=1, inplace=True)\n",
        "\n",
        "test = data.loc[~data.index.isin(train.index)].copy()\n",
        "y_test = (test['class'] == 4).astype(int)\n",
        "test.drop(['sample_code', 'class'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Eip8DHlV1IFd"
      },
      "outputs": [],
      "source": [
        "def create_svc(feature_columns, feature_layer_inputs, optimizer, loss=\"hinge\", metrics=[\"accuracy\"],\n",
        "               l2=0.01, output_dim=64, scale=None):\n",
        "  \n",
        "  regularizer = keras.regularizers.l2(l2)\n",
        "  feature_layer = keras.layers.DenseFeatures(feature_columns)\n",
        "  feature_layer_outputs = feature_layer(feature_layer_inputs)\n",
        "  norm = keras.layers.BatchNormalization()(feature_layer_outputs)\n",
        "  rff = RandomFourierFeatures(output_dim=output_dim, scale=scale, kernel_initializer=\"gaussian\")(norm)\n",
        "  outputs = keras.layers.Dense(1, \n",
        "                               kernel_initializer=\"normal\",\n",
        "                               kernel_regularizer=regularizer,\n",
        "                               activation=\"sigmoid\")(rff)\n",
        "                              \n",
        "  model = keras.Model(inputs=[v for v in feature_layer_inputs.values()], outputs=outputs)\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "EtXalBMjcaVM"
      },
      "outputs": [],
      "source": [
        "def define_feature_column_layers(data, categorical_cols, numeric_cols):\n",
        "    feature_columns = list()\n",
        "    feature_layer_inputs = dict()\n",
        "    \n",
        "    for feature_name in numeric_cols:\n",
        "        feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
        "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name)\n",
        "        \n",
        "    for feature_name in categorical_cols:\n",
        "        vocabulary = data[feature_name].unique()\n",
        "        cat = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)\n",
        "        cat_one_hot = tf.feature_column.indicator_column(cat)\n",
        "        feature_columns.append(cat_one_hot)\n",
        "        feature_layer_inputs[feature_name] = tf.keras.Input(shape=(1,), name=feature_name, dtype=tf.int32)\n",
        "        \n",
        "    return feature_columns, feature_layer_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7uZwXBT2dHY3"
      },
      "outputs": [],
      "source": [
        "def make_input_fn(data, label, num_epochs=10, shuffle=True, batch_size=256):\n",
        "    def input_function():\n",
        "        ds = tf.data.Dataset.from_tensor_slices((dict(data), label))\n",
        "        if shuffle:\n",
        "            ds = ds.shuffle(1000)\n",
        "        \n",
        "        ds = ds.batch(batch_size).repeat(num_epochs)\n",
        "        return ds\n",
        "    return input_function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YjJRcP1ZdDib"
      },
      "outputs": [],
      "source": [
        "import tempfile\n",
        "\n",
        "def canned_keras(model):\n",
        "    model_dir = tempfile.mkdtemp()\n",
        "    keras_estimator = keras.estimator.model_to_estimator(keras_model=model, model_dir=model_dir)\n",
        "    return keras_estimator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GR_pgQOt2zDe",
        "outputId": "e8332263-627a-424f-fcaf-d176b6e47f69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/keras/layers/normalization/batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:397: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'accuracy': 0.95714283, 'loss': 0.7258061, 'global_step': 1000}\n"
          ]
        }
      ],
      "source": [
        "categorical_cols = list()\n",
        "numeric_cols = ['clump_thickness', 'cell_size_uniformity', 'cell_shape_uniformity', 'marginal_adhesion', 'single_epithelial_cell_size',\n",
        "'bare_nuclei', 'bland_chromatin', 'normal_nucleoli', 'mitoses']\n",
        "\n",
        "feature_columns, feature_layer_inputs = define_feature_column_layers(data, categorical_cols, numeric_cols)\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.00005)\n",
        "model = create_svc(feature_columns, feature_layer_inputs, optimizer, loss=\"hinge\", l2=0.001, output_dim=512)\n",
        "\n",
        "estimator = canned_keras(model)\n",
        "\n",
        "train_input_fn = make_input_fn(train, y_train, num_epochs=500, batch_size=512)\n",
        "test_input_fn = make_input_fn(test, y_test, num_epochs=1, shuffle=False)\n",
        "\n",
        "estimator.train(train_input_fn)\n",
        "\n",
        "result = estimator.evaluate(test_input_fn)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwyCzlK5dp8H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
